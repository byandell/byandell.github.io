---
layout: page
title: Data Evolve
---

The noun `data` implies it is somehow static. However, data evolve in multiple ways, such as:

- data evolve through collecting anew and extant data editing
- data evolve in context of changing metadata and harmonizing to clean data
- measurement tools evolve, which change precision and focus, altering meaning
- methods to examine data evolve insights through summaries and visualizations
- questions about data evolve as the broader context changes
- "small data" augmented by "Big Data" evolve our ability to ask questions

One `datum` (a single piece of data) may not change, but everything around it may, and hence its importance and value may change. A datum to one person or situation may be a world of data to another--consider a painting, which to one person may represent a single datum in a collection, such as current owner, while to another person may contain a rich history of technique, setting, artist, and [provenance](https://www.nnlm.gov/guides/data-glossary/data-provenance).

I started thinking about how data evolve in our lives as a verb when I met
[Jhon Goes-in-Center](https://thebrintonmuseum.org/jhon-duane-goes-in-center-2020-brinton-101/)
at the
[Exploring Data Sovereignty Workshop](https://ncar.ucar.edu/exploring-data-sovereignty-workshop) in Feb 2024.
He was musing on how difficult it is to understand the noun `data` when his Lakota language is woven with verbs. Later, when we were looking out at the huge cottonwood trees surrounding the [hogan](https://www.sipi.edu/pdf/SIPI_Campus_Map.pdf) where we were meeting, he talked about how everything is related by `evolution`--how these very trees have evolved to be successful in this seemingly dry land just a short walk from the Rio Grande River.

## Software Evolves

Much earlier, in Fall 2017, I wrote a living (evolving) document as a guide for the language [R for teams in the data sciences](https://github.com/UW-Madison-DataScience/R_for_data_sciences). I organized it as a series of verbs--curate, visualize, organize, analyze, profile, and connect--to emphasize how to think about examining data with such a language.
About that time, I and others were asking, [What is Data Science?](/What-is-Data-Science/)
Interestingly, `science` is also a noun. [What is Science?](https://undsci.berkeley.edu/understanding-science-101/what-is-science/), a 101-level explanation from UC-Berkely, points out that science is both a body of knowledge (noun) and a process (verb) of studying the world.
Science is very much verb-driven, as is the incorporation of data science into science to make sense of complex patterns and relationships.

Someone once told me that
[software rots](https://towardsdatascience.com/why-and-how-software-systems-decay-fa7ec83c4ff3).
That is, software/code cannot be static, or it becomes irrelevant as the computing system, data and context around it evolve.
Consider a data project that benefits from software scripting (that is, most data projects),
here illustrated with the
[R language system](https://www.r-project.org/about.html).
My involvement is usually organic, starting with a few lines of code, developing likely into an
[R markdown document](https://rmarkdown.rstudio.com/)
that enables me to document my ideas and present visualizations, and even share results with others.
As the project develops, some code gets reused and is better organized as a
[function](https://www.sciencedirect.com/topics/computer-science/software-function).
Eventually, those functions get organized into a folder.
Ideally, each function of import is documented, say in R using
[Roxygen2](https://kbroman.org/pkg_primer/pages/docs.html).
As the collection of functions grow, it may be useful to organize them into an
[R package](https://cran.r-project.org/doc/manuals/R-exts.html),
particularly if I am using them for more than one project.
Typically, both for safety and sharing, it is helpful to put packages online, often in
[GitHub](https://happygitwithr.com/);
then others may view or use them as well.
Some projects have broader appeal and longevity, leading to submission to an archive such as
[CRAN](https://cran.rstudio.com/).
Packages used to be the goal, but now there is more recognized value in apps,
such as
[Shiny apps](https://shiny.posit.co/r/gallery/)
that in their simplest form can be created in a few minutes or hours.
More complicated platforms have emerged, such as
[Galaxy](https://galaxyproject.org/) and [RAMADDA](https://ramadda.org/),
that enable teams to collaboratively share data and code, possibly with
protections to respect
[data sovereignty](/Data-Sovereignty/).
This begs the question of emerging tools and platforms for AI, notably 
[large language models (LLMs)](https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f).

This organic process of developing useful tools to study data might be somewhat planned in advance, but typically, for me,
evolves based on insights and [collaboration](/pages/collaborate/) along the way.
Good collaboration includes documenting at every step, including notes on what is still
broken and what is hoped for future development.

Nowadays, I continue to rely on the lessons I learned building that guide and various projects in my
[GitHub repositories](https://github.com/byandell),
including this web site [byandell.github.io](https://github.com/byandell/byandell.github.io).
I now think more about how [teams](/pages/team/) evolve their relationship with data,
and their relationship with tools to make sense of data.
Data is really about people and about how we form our data-informed stories,
much in the way [Jaron Lanier](/Jaron-Lanier-There-is-no-AI/) thinks about AI.



